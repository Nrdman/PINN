{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f5e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import math\n",
    "#import scipy\n",
    "#import scipy.linalg  \n",
    "#import time\n",
    "#import scipy.sparse as sparse\n",
    "#import scipy.sparse.linalg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "#from pyDOE import lhs\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#import tensorflow_probability as tfp\n",
    "\n",
    "#Log: Implementing Eliptical PINN ADAM Aug 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe037bbb",
   "metadata": {},
   "source": [
    "Burgers Equation\n",
    "\n",
    "uy+uux= = 0, y positive\n",
    "\n",
    "solution: u(x, y) = x/(1+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f572f3c",
   "metadata": {},
   "source": [
    "Eliptical Equation with Boundary Condition\n",
    "\n",
    "u_yy+u_xx=0, x in [0,1], y in [0,1]\n",
    "\n",
    "\n",
    "\n",
    "u(0,x) = sin(c  x)\n",
    "\n",
    "u(1, x) = sin(c x)*exp(c)\n",
    "\n",
    "u(y, 0) =0\n",
    "\n",
    "u(y,1) = sin(c)exp(cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9648287",
   "metadata": {},
   "source": [
    "Exact Solution\n",
    "\n",
    "u(x, y) = sin(c x)exp(c y)\n",
    "\n",
    "uy = c sin(c x)exp(cy)\n",
    "\n",
    "uyy = c^2 sin(c x) exp(c y)\n",
    "\n",
    "\n",
    "ux = c cos(c x) exp(c y)\n",
    "\n",
    "uxx = -c^2 sin(c x) exp(c y)\n",
    "\n",
    "\n",
    "uxx+uyy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b084ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact solution\n",
    "def u_exact(data):\n",
    "    output = tf.math.sin(const*data[:, 0])*tf.math.sin(const*data[:, 1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7353f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact laplacian\n",
    "def f_exact(data):\n",
    "    output = -(2*const**2)*u_exact(data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107f838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2t(x,y):\n",
    "    #point to tensor for inputs\n",
    "    xin = np.atleast_1d(x)\n",
    "    yin = np.atleast_1d(y)\n",
    "    output = tf.constant(np.array([xin,yin]).T, dtype=tf.float32)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c65a32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_whole_inputs(xmin, xmax, ymin, ymax, xnum, ynum):\n",
    "    x = np.linspace(xmin, xmax, xnum)\n",
    "    y = np.linspace(ymin, ymax, ynum)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    xv = np.concatenate(xv)\n",
    "    yv = np.concatenate(yv)\n",
    "    data = p2t(xv, yv)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ea8eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bound_input(xmin, xmax, ymin, ymax, xnum, ynum):\n",
    "    xline = np.linspace(xmin, xmax, xnum)\n",
    "    yline = np.linspace(ymin, ymax, ynum)\n",
    "    top = p2t(xline, np.ones(xnum)*ymax)\n",
    "    bottom = p2t(xline, np.ones(xnum)*ymin)\n",
    "    left = p2t(np.ones(ynum)*xmin, yline)\n",
    "    right = p2t(np.ones(ynum)*xmax, yline)\n",
    "    output = tf.concat([top, bottom, left, right], 0)\n",
    "    output = tf.raw_ops.UniqueV2(x=output, axis = [0])[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "063b8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "        model=Sequential([Dense(width,activation='tanh',\n",
    "                                kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                                input_shape=(2,),name='H1')])\n",
    "        for i in range(depth):\n",
    "            model.add(Dense(width,activation='tanh',name='H'+str(i+2)))\n",
    "        model.add(Dense(1,name='output_layer'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eba5c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(model, data):\n",
    "    output = model(data)\n",
    "    return output[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afc62071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(model, data):\n",
    "    with tf.GradientTape(persistent = True) as tp1:\n",
    "        tp1.watch(data)\n",
    "        with tf.GradientTape() as tp2:\n",
    "            tp2.watch(data)\n",
    "            sol = u(model, data)\n",
    "        grad= tp2.gradient(sol, data)\n",
    "        u_x = grad[:, 0]\n",
    "        u_y = grad[:, 1]\n",
    "    u_xx = tp1.gradient(u_x, data)[:, 0]\n",
    "    u_yy = tp1.gradient(u_y, data)[:,1]\n",
    "    output = u_xx+u_yy\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0bf8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_system(model, u_hat, bound_init, bddata, intdata, f_exact_int, u_hat_bound): \n",
    "    PINN_loss = tf.reduce_mean(tf.math.square(f_exact_int-f(model, intdata)))\n",
    "    MSE_loss = tf.reduce_mean(tf.math.square(u_hat_bound-u(model, bddata)))\n",
    "    total_loss = PINN_loss+MSE_loss\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e4ecf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, u_hat, bound_init, bddata, intdata, max_it):\n",
    "    loss_history = []\n",
    "    f_exact_int = f_exact(intdata)\n",
    "    u_hat_bound = u_hat(bound_init, bddata)\n",
    "    for itr in range(max_it):\n",
    "        with tf.GradientTape() as tape:\n",
    "            train_loss = ode_system(model,u_hat, bound_init, bddata, intdata, f_exact_int, u_hat_bound)\n",
    "            grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "            optm.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            print(train_loss.numpy())\n",
    "            loss_history.append(train_loss.numpy())\n",
    "    return model, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9a32cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor_f(models, indata):\n",
    "    output = np.zeros(len(indata[:,0]))\n",
    "    for i in range(len(indata)):\n",
    "        datax = indata[i, 0]\n",
    "        datay = indata[i, 1]\n",
    "        el = subdomain_locator(Nvm, Nvn, datax, datay)\n",
    "        datapoint  = p2t(datax, datay)\n",
    "        model = models[el]\n",
    "        with tf.GradientTape(persistent = True) as tpf1:\n",
    "            tpf1.watch(datapoint)\n",
    "            with tf.GradientTape() as tpf2:\n",
    "                tpf2.watch(datapoint)\n",
    "                sol = model(datapoint) # make predictor function that returns f of that local NN instead of u\n",
    "            grad= tpf2.gradient(sol, datapoint)\n",
    "            u_x = grad[:, 0]\n",
    "            u_y = grad[:, 1]\n",
    "        u_xx = tpf1.gradient(u_x, datapoint)[:, 0]\n",
    "        u_yy = tpf1.gradient(u_y, datapoint)[:,1]\n",
    "        out = u_xx+u_yy\n",
    "        outarray = out.numpy()\n",
    "        output[i] = outarray\n",
    "    print(output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11b392d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_course(model,fine_models, max_it):\n",
    "    c_loss_history = []\n",
    "    \n",
    "    bddata = gen_bound_input(0, 1, 0, 1, sub_Nvm, sub_Nvn)\n",
    "    intdata = gen_whole_inputs(0, 1, 0, 1, sub_Nvm, sub_Nvn)\n",
    "    f_fine_int = predictor_f(fine_models, intdata)\n",
    "    f_exact_int = f_exact(intdata)\n",
    "    for itr in range(max_it):\n",
    "        with tf.GradientTape() as tape:\n",
    "            train_loss = c_ode_system(model, bddata, intdata, f_fine_int, f_exact_int)\n",
    "            grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "            optm.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        if itr % 10 == 0:\n",
    "            print(train_loss.numpy())\n",
    "            c_loss_history.append(train_loss.numpy())\n",
    "    return model, c_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55b470bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_ode_system(model, bddata, intdata, f_fine_int, f_exact_int):\n",
    "    int_loss = tf.reduce_mean(tf.math.square(f_exact_int-f_fine_int-f(model, intdata)))\n",
    "    \n",
    "    b_loss = tf.reduce_mean(tf.math.square(u(model, bddata)))\n",
    "    \n",
    "    #fine_loss = tf.reduce_mean(tf.math.square(u(model, intdata)-u_fine_int))\n",
    "    \n",
    "    total_loss = int_loss+b_loss #+lambda_f*fine_loss\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0a9f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subdomain_locator(Nvm, Nvn, x, y):\n",
    "    intx = x*Nvm\n",
    "    inty = y*Nvn\n",
    "\n",
    "    iintx=int(intx)\n",
    "    iinty=int(inty)\n",
    "    \n",
    "    colnum= np.sign(intx-iintx)*1+iintx+1-abs(np.sign(intx))\n",
    "\n",
    "    rownum= np.sign(inty-iinty)*1+iinty+1-abs(np.sign(inty))\n",
    "\n",
    "    i = int(colnum-1+(rownum-1)*Nvm)\n",
    "    #if i!=0:\n",
    "    #    print(i, x, y, colnum, rownum)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f035d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(models, indata):\n",
    "    output = np.zeros(len(indata[:,0]))\n",
    "    for i in range(len(indata)):\n",
    "        datax = indata[i, 0]\n",
    "        datay = indata[i, 1]\n",
    "        el = subdomain_locator(Nvm, Nvn, datax, datay)\n",
    "        model = models[el]\n",
    "        \n",
    "        #input_data = np.vstack([datapoint, [0,0]])\n",
    "\n",
    "        #input_data = tf.convert_to_tensor(input_data, np.float32)\n",
    "        #tensorpoint = tf.Variable([datapoint], dtype=tf.float32)\n",
    "        out = model(p2t(datax, datay))\n",
    "        outarray = out.numpy()\n",
    "        output[i] = outarray\n",
    "        \n",
    "        \n",
    "        #output[i] = u_exact(datapoint) #for testing\n",
    "    \n",
    "        \n",
    "        \n",
    "   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "136765c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bounds_coarse(u_coarse, models, DomNum, sub_x_min, sub_x_max, sub_y_min, sub_y_max, sub_Nvm, sub_Nvn, top_bounds, bottom_bounds, left_bounds, right_bounds, bound_init):\n",
    "    \n",
    "    for i in range(DomNum):\n",
    "        xline = np.linspace(sub_x_min[i], sub_x_max[i], sub_Nvm)\n",
    "        yline = np.linspace(sub_y_min[i], sub_y_max[i], sub_Nvn)\n",
    "        if sub_y_min[i] !=0:\n",
    "            indata = p2t(xline, np.full(len(xline), sub_y_min[i]))\n",
    "            bottom_bounds[i, :] = predictor(models, indata)+u_coarse(indata).numpy()[:,0]\n",
    "        if sub_y_max[i] !=1:\n",
    "            indata = p2t(xline, np.full(len(xline), sub_y_max[i]))\n",
    "            top_bounds[i, :] = predictor(models, indata)+u_coarse(indata).numpy()[:,0]\n",
    "        if sub_x_min[i] !=0:\n",
    "            indata = p2t(np.full(len(yline), sub_x_min[i]), yline)\n",
    "            left_bounds[i, :] = predictor(models, indata)+u_coarse(indata).numpy()[:,0]\n",
    "        if sub_x_max[i] !=1:\n",
    "            indata = p2t(np.full(len(yline), sub_x_max[i]), yline)\n",
    "            right_bounds[i,:] = predictor(models, indata)+u_coarse(indata).numpy()[:,0]\n",
    "\n",
    "    return (top_bounds, bottom_bounds, left_bounds, right_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a4ea84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliptic_PINN(model, u_hat, bound_init, top_bounds, bottom_bounds, left_bounds, right_bounds, xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvn):\n",
    "    \n",
    "    \n",
    "    bound_data = gen_bound_input(xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvm)\n",
    "    whole_data = gen_whole_inputs(xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvn)\n",
    "    \n",
    "    [model, sub_loss] = train_model(model,u_hat, bound_init, bound_data, whole_data, max_it)\n",
    "\n",
    "    \n",
    "    return model, sub_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b159ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepDDM(Nvm,Nvn, h_x, h_y, epochs, sub_Nvm, sub_Nvn, bound_init):\n",
    "    #Nvm = number of sub domains on x  axis\n",
    "    #Nvn = number of sub domains  on y axis\n",
    "        #1 on both means there is only the original domain\n",
    "    \n",
    "    #sub_Nvm = number of elements within subdomains on  x axis for use in the net training \n",
    "    #sub_Nvn = number of elements within subdomains on  y axis for use in the net training\n",
    "        #1 on both means just corners would be used\n",
    "    \n",
    "    \n",
    "    #Nvm*Nvn= number of subdomains\n",
    "    #h is percentage of overlap in the relevant axis\n",
    "        #note h_x<=1, h_y<=1\n",
    "    #Space is [0,1] by [0,1]\n",
    "    \n",
    "    #connnectivity matrix, as in what subdomains are connected\n",
    "    #is boundary matrix\n",
    "    #range of the various subdomains\n",
    "    \n",
    "    len_x = 1/(Nvm) # length of the subdivisions on x axis\n",
    "    len_y = 1/(Nvn) #length of the subdivisions on y axis\n",
    "    global domain_loss\n",
    "    global l2max\n",
    "    l2max = []\n",
    "    DomNum = Nvm*Nvn\n",
    "    sub_x_min = np.empty(DomNum) \n",
    "    sub_x_max = np.empty(DomNum)\n",
    "    sub_y_min = np.empty(DomNum)\n",
    "    sub_y_max = np.empty(DomNum)\n",
    "    el_rownum = np.empty(DomNum)\n",
    "    el_colnum = np.empty(DomNum)\n",
    "    \n",
    "    if 0==Nvm-1:\n",
    "        sub_x_max = np.ones(DomNum)\n",
    "        sub_x_min = np.zeros(DomNum)\n",
    "    else:\n",
    "        for i in range(DomNum):\n",
    "        #generates which row, column each element is in\n",
    "            el_colnum[i] = np.mod(i,Nvm)\n",
    "            if el_colnum[i] == 0:\n",
    "                sub_x_max[i] = (el_colnum[i]+1+h_x)*len_x\n",
    "                sub_x_min[i] = (el_colnum[i])*len_x\n",
    "            elif el_colnum[i] == Nvm-1:\n",
    "                sub_x_min[i] = (el_colnum[i]-h_x)*len_x\n",
    "                sub_x_max[i] = (el_colnum[i]+1)*len_x\n",
    "            else:\n",
    "                sub_x_min[i] = (el_colnum[i]-h_x)*len_x\n",
    "                sub_x_max[i] = (el_colnum[i]+1+h_x)*len_x\n",
    "\n",
    "    if 0==Nvn-1:\n",
    "        sub_y_max = np.ones(DomNum)\n",
    "        sub_y_min = np.zeros(DomNum)\n",
    "    else:\n",
    "        for i in range(DomNum):\n",
    "        #generates which row, column each element is in\n",
    "            el_rownum[i] = int(i/Nvm) \n",
    "\n",
    "            if el_rownum[i]==0:\n",
    "                sub_y_max[i] = (el_rownum[i]+1+h_y)*len_y\n",
    "                sub_y_min[i] = el_rownum[i]*len_y\n",
    "            elif el_rownum[i]==Nvn-1:\n",
    "                sub_y_min[i] = (el_rownum[i]-h_y)*len_y\n",
    "                sub_y_max[i] = (el_rownum[i]+1)*len_y\n",
    "            else:\n",
    "                sub_y_min[i] = (el_rownum[i]-h_y)*len_y\n",
    "                sub_y_max[i] = (el_rownum[i]+1+h_y)*len_y\n",
    "\n",
    "        \n",
    "    u_pred = np.zeros([Nvm*sub_Nvm, Nvn*sub_Nvn])    \n",
    "    top_bounds = np.zeros([DomNum , sub_Nvm])\n",
    "    bottom_bounds = np.zeros([DomNum , sub_Nvm]) \n",
    "    left_bounds = np.zeros([DomNum, sub_Nvn]) \n",
    "    right_bounds = np.zeros([DomNum, sub_Nvn]) \n",
    "    \n",
    "    models = [None]*DomNum\n",
    "    dom_loss_history = np.zeros(epochs)\n",
    "    coarse_loss_history = np.zeros(epochs)\n",
    "    \n",
    "    #initialize boundaries\n",
    "    xzeros = np.zeros(sub_Nvm)\n",
    "    yzeros = np.zeros(sub_Nvn)\n",
    "    xones = np.ones(sub_Nvm)\n",
    "    yones = np.ones(sub_Nvn)\n",
    "    u_coarse = get_model()\n",
    "    for i in range(DomNum):\n",
    "        xline = np.linspace(sub_x_min[i], sub_x_max[i], sub_Nvm)\n",
    "        yline = np.linspace(sub_y_min[i], sub_y_max[i], sub_Nvn)\n",
    "        \n",
    "        if sub_y_min[i] ==0:\n",
    "            bottom_bounds[i, :] = u_exact(p2t(xline, xzeros))\n",
    "            #for j in range(sub_Nvm):\n",
    "             #   bottom_bounds[i, j] = u_exact(p2t(xline[j], 0))\n",
    "        else:\n",
    "            bottom_bounds[i, :] = bound_init(p2t(xline, xzeros))\n",
    "            #for j in range(sub_Nvm):\n",
    "            #   bottom_bounds[i, j] = bound_init([xline[j], sub_y_min[i]])\n",
    "        if sub_y_max[i] ==1:\n",
    "            top_bounds[i, :] = u_exact(p2t(xline, xones))\n",
    "            #for j in range(sub_Nvm):\n",
    "            #    top_bounds[i,j] = u_exact(p2t(xline[j], 1))\n",
    "        else:\n",
    "            top_bounds[i, :] = bound_init(p2t(xline, xones))\n",
    "\n",
    "            #for j in range(sub_Nvm):\n",
    "                #top_bounds[i,j] = bound_init([xline[j], sub_y_max[i]])\n",
    "\n",
    "        if sub_x_min[i]==0:\n",
    "            left_bounds[i, :] = u_exact(p2t(yzeros, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #    left_bounds[i, j] =  u_exact(p2t(0, yline[j]))\n",
    "        else:\n",
    "            left_bounds[i, :] = bound_init(p2t(yzeros, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #   left_bounds[i, j] = bound_init([sub_x_min[i], yline[j]])\n",
    "                \n",
    "        if sub_x_max[i]==1:\n",
    "            right_bounds[i, :] = u_exact(p2t(yones, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #    right_bounds[i, j] = u_exact(p2t(1, yline[j]))\n",
    "        else:\n",
    "            right_bounds[i, :] = bound_init(p2t(yones, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #    right_bounds[i, j] = bound_init([sub_x_max[i], yline[j]])\n",
    "   \n",
    "    #exact_l2 = f_exact(gen_whole_inputs(0, 1, 0, 1, 100, 100))\n",
    "    error_history = np.zeros(epochs)\n",
    "    #xl2 = np.linspace(0, 1, 100)\n",
    "    #yl2 = np.linspace(0, 1, 100)\n",
    "\n",
    "    #Xl2, Yl2 = np.meshgrid(xl2,yl2) \n",
    "    #Xl2_star=np.hstack((Xl2.flatten()[:,None],Yl2.flatten()[:,None]))\n",
    "    \n",
    "    \n",
    "    def u_hat(bound_init, data):\n",
    "        approx = bound_init(data)\n",
    "        if type(approx) == np.ndarray:\n",
    "            output = approx\n",
    "        else:\n",
    "            output = approx.numpy()\n",
    "        for i in range(len(data)):\n",
    "            if data[i, 0]==0 or data[i, 1]==0 or data[i, 1]==1 or data[i, 1]==1:\n",
    "                output[i] = u_exact(tf.expand_dims(data[i, :], axis = 0))\n",
    "\n",
    "        return output\n",
    "    for i in range(DomNum):\n",
    "        models[i] = get_model()\n",
    "        \n",
    "    tol_data = gen_bound_input(0, 1, 0, 1, 100, 100)\n",
    "    flag=False\n",
    "    epoch=0\n",
    "    while epoch<epochs and flag==False: \n",
    "        if epoch ==1: #the second epoch, updates the initializer to be the predictor, so boundary info exchange happens\n",
    "            def bound_init2(data):\n",
    "                output= predictor(models, data)\n",
    "                return output\n",
    "            bound_init = bound_init2\n",
    "\n",
    "        for i in range(DomNum):\n",
    "            print(\"Fine Epoch: \"+str(epoch+1) +\"  Subdomain: \"+str(i+1))\n",
    "            (update_model, loss_update) = Eliptic_PINN(models[i], u_hat,bound_init,  top_bounds[i, :], bottom_bounds[i, :], left_bounds[i, :], right_bounds[i, :], sub_x_min[i], sub_x_max[i], sub_y_min[i], sub_y_max[i], sub_Nvm, sub_Nvn)\n",
    "            models[i] = update_model \n",
    "            \n",
    "            dom_loss_history[epoch] = dom_loss_history[epoch]+loss_update[-1]\n",
    "        #Xl2_star=np.hstack((Xl2.flatten()[:,None],Yl2.flatten()[:,None]))\n",
    "        print(\"Coarse Epoch: \", epoch+1)\n",
    "        (u_coarse, c_loss_update) = train_course(u_coarse, models, max_it)\n",
    "        coarse_loss_history[epoch] += c_loss_update[-1]\n",
    "        error_history[epoch] = get_l2(models)\n",
    "        \n",
    "        \n",
    "        #network tolerance criteria for stopping\n",
    "        if epoch==0:\n",
    "            prev_net = predictor(models, tol_data)\n",
    "            prev_norm = tf.reduce_mean(tf.math.square(prev_net))\n",
    "        else:\n",
    "            new_net = predictor(models, tol_data)\n",
    "            net_diff = tf.reduce_mean(tf.math.square(prev_net -new_net))\n",
    "            new_norm = tf.reduce_mean(tf.math.square(new_net))\n",
    "            rel_net_diff = net_diff/min(new_norm, prev_norm)\n",
    "            if rel_net_diff<net_tol:\n",
    "                print(\"Network has converged\")\n",
    "                flag=True\n",
    "            else:\n",
    "                prev_net = new_net\n",
    "                prev_norm = new_norm\n",
    "                \n",
    "        if error_history[epoch]<error_tol:\n",
    "            flag = True\n",
    "            print(\"Error is below tolerance.\")\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        #update bounds with new guesses   \n",
    "        (new_top_bounds, new_bottom_bounds, new_left_bounds, new_right_bounds)= update_bounds_coarse(u_coarse, models, DomNum, sub_x_min, sub_x_max, sub_y_min, sub_y_max, sub_Nvm, sub_Nvn, top_bounds, bottom_bounds, left_bounds, right_bounds, bound_init)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        epoch+=1\n",
    "    \n",
    "    dom_loss_history = dom_loss_history/(DomNum) #Averages over subdomains\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    for i in range(DomNum):\n",
    "        plt.vlines(x=[sub_x_min[i], sub_x_max[i]], ymin=0, ymax=1)\n",
    "        plt.hlines(y=[sub_y_min[i], sub_y_max[i]], xmin=0, xmax=1)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(dom_loss_history[np.nonzero(dom_loss_history)], label=\"Fine Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(coarse_loss_history[np.nonzero(coarse_loss_history)], label=\"Coarse Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(error_history[np.nonzero(error_history)], label =\"Relative L2 Error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Fine Loss: \"+str(dom_loss_history[np.nonzero(dom_loss_history)]))\n",
    "    print(\"Coarse Loss: \"+ str(coarse_loss_history[np.nonzero(coarse_loss_history)]))\n",
    "    print(\"Error \" +str(error_history[np.nonzero(error_history)]))\n",
    "    np.savetxt(\"RC_Loss_and_error.txt\", (dom_loss_history[np.nonzero(dom_loss_history)],coarse_loss_history[np.nonzero(coarse_loss_history)], error_history[np.nonzero(error_history)]), delimiter =\", \", header= \"Fine Loss, Coarse Loss, Error\")\n",
    "    \n",
    "    return models\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95ea3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2(models):\n",
    "    data = gen_whole_inputs(0,1, 0,1, 100, 100)\n",
    "    pred = predictor(models, data)\n",
    "    exact = u_exact(data)\n",
    "    #pred = pred.reshape([100, 100])\n",
    "    error = np.linalg.norm(exact-pred)/np.linalg.norm(exact)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99747724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(models):\n",
    "    data = gen_whole_inputs(0, 1, 0, 1, 100, 100)\n",
    "    approx = predictor(models, data)\n",
    "    exact = u_exact(data).numpy()\n",
    "    abs_error = abs(exact - approx)\n",
    "    MAE_error = (abs_error).mean()\n",
    "    print(\"Mean Absolute Error: \" + str(MAE_error))\n",
    "    rel_L2_err = np.linalg.norm(exact-approx)/np.linalg.norm(exact) \n",
    "    print(\"Relative L2 Error: \" + str(rel_L2_err))\n",
    "    print(\"Error Max \"+ str(abs_error.max()))\n",
    "    print(\"Error Min \"+ str(abs_error.min()))\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    ax = plt.subplot(3, 1, 1)\n",
    "    plt.tricontourf(x, y, abs_error ,100)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(label = \"Absolute Error\")\n",
    "    #plt.plot()\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.tricontourf(x, y, approx ,100)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(label = \"Predicted\")\n",
    "    np.savetxt(\"RC_Approx.txt\", approx)\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.tricontourf(x, y, exact ,100)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(label = \"Exact\")\n",
    "    np.savetxt(\"RC_Exact.txt\", exact)\n",
    "\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31136fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xsplice_plt(models, x):\n",
    "    y = np.linspace(0, 1, 100) \n",
    "    data= p2t(np.full(100, x), y)\n",
    "    exact = u_exact(data)\n",
    "    \n",
    "    plt.plot(exact, label = \"X = \"+str(x))\n",
    "    plt.plot(predictor(models, data), label = \"X Approx\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c41f171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ysplice_plt(models, y):\n",
    "    x = np.linspace(0, 1, 100) \n",
    "\n",
    "    data = p2t( x, np.full(100, y))\n",
    "\n",
    "\n",
    "    plt.plot(u_exact(data), label = \"Y = \"+str(y))\n",
    "    plt.plot(predictor(models, data), label = \"Y Approx\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1198730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_init(data):\n",
    "    return np.zeros(len(data))\n",
    "#for exact initializer put u_exact as the initializer\n",
    "#def random_init(data):\n",
    "#    return np.random.rand(len(data))\n",
    "def avg_init(x, y):\n",
    "    avg = 0.25*((1-x)*u_exact([x, 0])+x*u_exact([x, 1])+(1-y)*u_exact([0, y])+y*u_exact([1, y]))\n",
    "    return avg\n",
    "#def noisy_init(data):\n",
    " #   return u_exact(data)+noise*random_init(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9036e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvm = 3 #number of subintervals along x axis\n",
    "Nvn = 3 #number of subintervals along y axis\n",
    "h_x = 0.2 #percentage of overlap (<=1)\n",
    "h_y = 0.2 #percentage of overlap (<=1)\n",
    "epochs = 100\n",
    "sub_Nvm = 100 #mesh for PINN training\n",
    "sub_Nvn = 100\n",
    "max_it = 100 #max_it for PINN training\n",
    "initializer = zero_init #u_exact, zero_init, random_init, avg_init, noisy_init\n",
    "global noise\n",
    "noise = 0.05 #only for noisy initializer\n",
    "#reset_models_betweeen_epochs = True\n",
    "optm = tf.keras.optimizers.legacy.Adam(amsgrad=True)\n",
    "net_tol= 1e-3 #tolerance for network convergeance \n",
    "error_tol = 0.1 #tolerance for error\n",
    "\n",
    "coarse_decay = 0.8 #between 0 and 1. Adjust how fast coarse network influence decays\n",
    "\n",
    "\n",
    "global per_collocation\n",
    "global per_interior\n",
    "global width #width in NN models\n",
    "global depth #depth in NN models\n",
    "global const #PDE constant\n",
    "global int_weight #weight for interior loss, between 0 and 1, higher means more weight on PDE loss than boundary loss\n",
    "int_weight = 0.5\n",
    "const = 3.141592653589793 #math.pi\n",
    "per_collocation = 0.5\n",
    "per_interior = 0.5\n",
    "width  = 20\n",
    "depth  = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93bc5d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Epoch: 1  Subdomain: 1\n",
      "69.9157\n",
      "40.260094\n",
      "19.255463\n",
      "15.728298\n",
      "11.260887\n",
      "6.774018\n",
      "4.0517683\n",
      "2.0685124\n",
      "1.1366857\n",
      "1.0402411\n",
      "Fine Epoch: 1  Subdomain: 2\n",
      "119.65555\n",
      "35.71056\n",
      "34.235443\n",
      "28.362703\n",
      "20.976774\n",
      "4.539829\n",
      "3.8104527\n",
      "2.7335536\n",
      "1.8564831\n",
      "1.2979535\n",
      "Fine Epoch: 1  Subdomain: 3\n",
      "58.215675\n",
      "20.997702\n",
      "12.849425\n",
      "10.066545\n",
      "5.9596395\n",
      "3.3939857\n",
      "2.4034824\n",
      "2.0924366\n",
      "1.8383036\n",
      "1.6708257\n",
      "Fine Epoch: 1  Subdomain: 4\n",
      "122.89459\n",
      "29.729536\n",
      "4.7555437\n",
      "3.7436066\n",
      "1.7778428\n",
      "1.4442706\n",
      "1.1304113\n",
      "1.0564218\n",
      "0.9677651\n",
      "0.9138119\n",
      "Fine Epoch: 1  Subdomain: 5\n",
      "267.0264\n",
      "76.6399\n",
      "25.90387\n",
      "8.670925\n",
      "5.5721936\n",
      "3.2254362\n",
      "2.7760353\n",
      "2.3326979\n",
      "2.0687602\n",
      "1.866673\n",
      "Fine Epoch: 1  Subdomain: 6\n",
      "113.69914\n",
      "20.462875\n",
      "7.9107003\n",
      "5.5676827\n",
      "3.900395\n",
      "3.3014522\n",
      "2.964855\n",
      "2.7858005\n",
      "2.6324449\n",
      "2.4627929\n",
      "Fine Epoch: 1  Subdomain: 7\n",
      "58.479477\n",
      "12.7980175\n",
      "8.776554\n",
      "4.078543\n",
      "2.9886875\n",
      "1.6518528\n",
      "1.4232571\n",
      "1.2170995\n",
      "1.0955406\n",
      "0.9913742\n",
      "Fine Epoch: 1  Subdomain: 8\n",
      "131.50656\n",
      "37.081676\n",
      "11.365423\n",
      "3.5653284\n",
      "2.8738053\n",
      "2.3261456\n",
      "1.9275215\n",
      "1.6733215\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14860/1613703577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1234\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDeepDDM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNvn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_Nvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_Nvn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14860/4228279815.py\u001b[0m in \u001b[0;36mDeepDDM\u001b[1;34m(Nvm, Nvn, h_x, h_y, epochs, sub_Nvm, sub_Nvn, bound_init)\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDomNum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fine Epoch: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\"  Subdomain: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[1;33m(\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_update\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEliptic_PINN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbound_init\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mtop_bounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbottom_bounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_bounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_bounds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_x_min\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_x_max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_y_min\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_y_max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_Nvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_Nvn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m             \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14860/1247130713.py\u001b[0m in \u001b[0;36mEliptic_PINN\u001b[1;34m(model, u_hat, bound_init, top_bounds, bottom_bounds, left_bounds, right_bounds, xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvn)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mwhole_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_whole_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mymax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_Nvm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_Nvn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msub_loss\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwhole_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_it\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14860/312785054.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, u_hat, bound_init, bddata, intdata, max_it)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mode_system\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbound_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbddata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_exact_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_hat_bound\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0moptm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[0;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[0;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1738\u001b[0m   \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6010\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6011\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6012\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6013\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6014\u001b[0m         transpose_b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "models = DeepDDM(Nvm, Nvn, h_x, h_y, epochs, sub_Nvm, sub_Nvn, initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaaa144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0827567",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsplice_plt(models, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ysplice_plt(models, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6925ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
