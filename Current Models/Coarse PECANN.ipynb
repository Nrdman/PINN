{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "97f5e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import math\n",
    "#import scipy\n",
    "#import scipy.linalg  \n",
    "#import time\n",
    "#import scipy.sparse as sparse\n",
    "#import scipy.sparse.linalg\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "#from pyDOE import lhs\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#import tensorflow_probability as tfp\n",
    "\n",
    "#Log: Implementing Eliptical PINN ADAM Aug 2023\n",
    "#https://www.sciencedirect.com/science/article/pii/S0021999122003631?via%3Dihub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe037bbb",
   "metadata": {},
   "source": [
    "Burgers Equation\n",
    "\n",
    "uy+uux= = 0, y positive\n",
    "\n",
    "solution: u(x, y) = x/(1+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f572f3c",
   "metadata": {},
   "source": [
    "Eliptical Equation with Boundary Condition\n",
    "\n",
    "u_yy+u_xx=0, x in [0,1], y in [0,1]\n",
    "\n",
    "\n",
    "\n",
    "u(0,x) = sin(c  x)\n",
    "\n",
    "u(1, x) = sin(c x)*exp(c)\n",
    "\n",
    "u(y, 0) =0\n",
    "\n",
    "u(y,1) = sin(c)exp(cy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9648287",
   "metadata": {},
   "source": [
    "Exact Solution\n",
    "\n",
    "u(x, y) = sin(c x)exp(c y)\n",
    "\n",
    "uy = c sin(c x)exp(cy)\n",
    "\n",
    "uyy = c^2 sin(c x) exp(c y)\n",
    "\n",
    "\n",
    "ux = c cos(c x) exp(c y)\n",
    "\n",
    "uxx = -c^2 sin(c x) exp(c y)\n",
    "\n",
    "\n",
    "uxx+uyy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b084ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact solution\n",
    "def u_exact(data):\n",
    "    output = tf.math.sin(const*data[:, 0])*tf.math.sin(const*data[:, 1])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7353f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exact laplacian\n",
    "def f_exact(data):\n",
    "    output = -(2*const**2)*u_exact(data)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "107f838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p2t(x,y):\n",
    "    #point to tensor for inputs\n",
    "    xin = np.atleast_1d(x)\n",
    "    yin = np.atleast_1d(y)\n",
    "    output = tf.constant(np.array([xin,yin]).T, dtype=tf.float32)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c65a32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_whole_inputs(xmin, xmax, ymin, ymax, xnum, ynum):\n",
    "    x = np.linspace(xmin, xmax, xnum)\n",
    "    y = np.linspace(ymin, ymax, ynum)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    xv = np.concatenate(xv)\n",
    "    yv = np.concatenate(yv)\n",
    "    data = p2t(xv, yv)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9ea8eaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_bound_input(xmin, xmax, ymin, ymax, xnum, ynum):\n",
    "    xline = np.linspace(xmin, xmax, xnum)\n",
    "    yline = np.linspace(ymin, ymax, ynum)\n",
    "    top = p2t(xline, np.ones(xnum)*ymax)\n",
    "    bottom = p2t(xline, np.ones(xnum)*ymin)\n",
    "    left = p2t(np.ones(ynum)*xmin, yline)\n",
    "    right = p2t(np.ones(ynum)*xmax, yline)\n",
    "    output = tf.concat([top, bottom, left, right], 0)\n",
    "    output = tf.raw_ops.UniqueV2(x=output, axis = [0])[0]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "063b8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "        model=Sequential([Dense(width,activation='tanh',\n",
    "                                kernel_initializer=tf.keras.initializers.GlorotNormal(),\n",
    "                                input_shape=(2,),name='H1')])\n",
    "        for i in range(depth):\n",
    "            model.add(Dense(width,activation='tanh',name='H'+str(i+2)))\n",
    "        model.add(Dense(1,name='output_layer'))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "eba5c39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def u(model, data):\n",
    "    output = model(data)\n",
    "    return output[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "afc62071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(model, data):\n",
    "    with tf.GradientTape(persistent = True) as tp1:\n",
    "        tp1.watch(data)\n",
    "        with tf.GradientTape() as tp2:\n",
    "            tp2.watch(data)\n",
    "            sol = u(model, data)\n",
    "        grad= tp2.gradient(sol, data)\n",
    "        u_x = grad[:, 0]\n",
    "        u_y = grad[:, 1]\n",
    "    u_xx = tp1.gradient(u_x, data)[:, 0]\n",
    "    u_yy = tp1.gradient(u_y, data)[:,1]\n",
    "    output = u_xx+u_yy\n",
    "    return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e0bf8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_system(model, u_hat, bound_init, bddata, intdata, f_exact_int, u_hat_bound, pen_param, lag_mult): \n",
    "    PINN_loss = tf.reduce_mean(tf.math.square(f_exact_int-f(model, intdata)))\n",
    "    MSE_loss = tf.reduce_mean(tf.math.square(u_hat_bound-u(model, bddata)))\n",
    "    \n",
    "    total_loss = PINN_loss+lag_mult*MSE_loss+0.5*pen_param*MSE_loss*MSE_loss\n",
    "    lag_mult += pen_param*MSE_loss #update according to formula (13) of PECANN paper\n",
    "    return total_loss, lag_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7e4ecf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, u_hat, bound_init, bddata, intdata, max_it, pen_param, max_pen_param, lag_mult):\n",
    "    loss_history = []\n",
    "    f_exact_int = f_exact(intdata)\n",
    "    u_hat_bound = u_hat(bound_init, bddata)\n",
    "    for itr in range(max_it):\n",
    "        with tf.GradientTape() as tape:\n",
    "            (train_loss, lag_mult) = ode_system(model,u_hat, bound_init, bddata, intdata, f_exact_int, u_hat_bound, pen_param, lag_mult)\n",
    "            grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "            optm.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        pen_param = min(2*pen_param, max_pen_param)\n",
    "\n",
    "\n",
    "        if itr % 10 == 0:\n",
    "            print(train_loss.numpy())\n",
    "            loss_history.append(train_loss.numpy())\n",
    "    return model, loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "11b392d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_course(model,fine_models, max_it, pen_param, max_pen_param, lag_mult1, lag_mult2):\n",
    "    c_loss_history = []\n",
    "    \n",
    "    bddata = gen_bound_input(0, 1, 0, 1, sub_Nvm, sub_Nvn)\n",
    "    intdata = gen_whole_inputs(0, 1, 0, 1, sub_Nvm, sub_Nvn)\n",
    "    exact_bounds = u_exact(bddata)\n",
    "    u_fine_int = predictor(fine_models, intdata)\n",
    "    f_exact_int = f_exact(intdata)\n",
    "    for itr in range(max_it):\n",
    "        with tf.GradientTape() as tape:\n",
    "            (train_loss, lag_mult1, lag_mult2) = c_ode_system(model, fine_models, bddata, intdata, exact_bounds, u_fine_int, f_exact_int, pen_param, lag_mult1, lag_mult2)\n",
    "            grads = tape.gradient(train_loss, model.trainable_variables)\n",
    "            optm.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        pen_param = min(2*pen_param, max_pen_param)\n",
    "        if itr % 10 == 0:\n",
    "            print(train_loss.numpy())\n",
    "            c_loss_history.append(train_loss.numpy())\n",
    "    return model, c_loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "55b470bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_ode_system(model, fine_models, bddata, intdata, exact_bounds, u_fine_int, f_exact_int, pen_param, lag_mult1, lag_mult2):\n",
    "    int_loss = tf.reduce_mean(tf.math.square(f_exact_int-f(model, intdata)))\n",
    "    \n",
    "    b_loss = tf.reduce_mean(tf.math.square(exact_bounds-u(model, bddata)))\n",
    "    \n",
    "    f_loss = tf.reduce_mean(tf.math.square(u(model, intdata)-u_fine_int))\n",
    "    \n",
    "    total_loss = int_loss+lag_mult1*b_loss+lag_mult2*f_loss+0.5*pen_param*(b_loss*b_loss+f_loss*f_loss)\n",
    "    lag_mult1+=pen_param*b_loss\n",
    "    lag_mult2 +=pen_param*f_loss\n",
    "    return total_loss, lag_mult1, lag_mult2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f0a9f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def subdomain_locator(Nvm, Nvn, x, y):\n",
    "    intx = x*Nvm\n",
    "    inty = y*Nvn\n",
    "\n",
    "    iintx=int(intx)\n",
    "    iinty=int(inty)\n",
    "    \n",
    "    colnum= np.sign(intx-iintx)*1+iintx+1-abs(np.sign(intx))\n",
    "\n",
    "    rownum= np.sign(inty-iinty)*1+iinty+1-abs(np.sign(inty))\n",
    "\n",
    "    i = int(colnum-1+(rownum-1)*Nvm)\n",
    "    #if i!=0:\n",
    "    #    print(i, x, y, colnum, rownum)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f035d517",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(models, indata):\n",
    "    output = np.zeros(len(indata[:,0]))\n",
    "    for i in range(len(indata)):\n",
    "        datax = indata[i, 0]\n",
    "        datay = indata[i, 1]\n",
    "        el = subdomain_locator(Nvm, Nvn, datax, datay)\n",
    "        model = models[el]\n",
    "        \n",
    "        #input_data = np.vstack([datapoint, [0,0]])\n",
    "\n",
    "        #input_data = tf.convert_to_tensor(input_data, np.float32)\n",
    "        #tensorpoint = tf.Variable([datapoint], dtype=tf.float32)\n",
    "        out = model(p2t(datax, datay))\n",
    "        outarray = out.numpy()\n",
    "        output[i] = outarray\n",
    "        \n",
    "        \n",
    "        #output[i] = u_exact(datapoint) #for testing\n",
    "    \n",
    "        \n",
    "        \n",
    "   \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "136765c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_bounds_coarse(u_coarse, lambda_c, models, DomNum, sub_x_min, sub_x_max, sub_y_min, sub_y_max, sub_Nvm, sub_Nvn, top_bounds, bottom_bounds, left_bounds, right_bounds, bound_init):\n",
    "    \n",
    "    for i in range(DomNum):\n",
    "        xline = np.linspace(sub_x_min[i], sub_x_max[i], sub_Nvm)\n",
    "        yline = np.linspace(sub_y_min[i], sub_y_max[i], sub_Nvn)\n",
    "        if sub_y_min[i] !=0:\n",
    "            indata = p2t(xline, np.full(len(xline), sub_y_min[i]))\n",
    "            bottom_bounds[i, :] = (1-lambda_c)*predictor(models, indata)+lambda_c*u_coarse(indata).numpy()[:,0]\n",
    "        if sub_y_max[i] !=1:\n",
    "            indata = p2t(xline, np.full(len(xline), sub_y_max[i]))\n",
    "            top_bounds[i, :] = (1-lambda_c)*predictor(models, indata)+lambda_c*u_coarse(indata).numpy()[:,0]\n",
    "        if sub_x_min[i] !=0:\n",
    "            indata = p2t(np.full(len(yline), sub_x_min[i]), yline)\n",
    "            left_bounds[i, :] = (1-lambda_c)*predictor(models, indata)+lambda_c*u_coarse(indata).numpy()[:,0]\n",
    "        if sub_x_max[i] !=1:\n",
    "            indata = p2t(np.full(len(yline), sub_x_max[i]), yline)\n",
    "            right_bounds[i,:] = (1-lambda_c)*predictor(models, indata)+lambda_c*u_coarse(indata).numpy()[:,0]\n",
    "\n",
    "    return (top_bounds, bottom_bounds, left_bounds, right_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "a4ea84b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eliptic_PINN(model, u_hat, bound_init, top_bounds, bottom_bounds, left_bounds, right_bounds, xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvn, pen_param, max_pen_param,lag_mult):\n",
    "    \n",
    "    \n",
    "    bound_data = gen_bound_input(xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvm)\n",
    "    whole_data = gen_whole_inputs(xmin, xmax, ymin, ymax, sub_Nvm, sub_Nvn)\n",
    "    \n",
    "    [model, sub_loss] = train_model(model,u_hat, bound_init, bound_data, whole_data, max_it, pen_param, max_pen_param, lag_mult)\n",
    "\n",
    "    \n",
    "    return model, sub_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "b159ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DeepDDM(Nvm,Nvn, h_x, h_y, epochs, sub_Nvm, sub_Nvn, bound_init, max_pen_param, pen_param_0, lag_mult_0):\n",
    "    #Nvm = number of sub domains on x  axis\n",
    "    #Nvn = number of sub domains  on y axis\n",
    "        #1 on both means there is only the original domain\n",
    "    \n",
    "    #sub_Nvm = number of elements within subdomains on  x axis for use in the net training \n",
    "    #sub_Nvn = number of elements within subdomains on  y axis for use in the net training\n",
    "        #1 on both means just corners would be used\n",
    "    \n",
    "    \n",
    "    #Nvm*Nvn= number of subdomains\n",
    "    #h is percentage of overlap in the relevant axis\n",
    "        #note h_x<=1, h_y<=1\n",
    "    #Space is [0,1] by [0,1]\n",
    "    \n",
    "    #connnectivity matrix, as in what subdomains are connected\n",
    "    #is boundary matrix\n",
    "    #range of the various subdomains\n",
    "    \n",
    "    len_x = 1/(Nvm) # length of the subdivisions on x axis\n",
    "    len_y = 1/(Nvn) #length of the subdivisions on y axis\n",
    "    global domain_loss\n",
    "    global l2max\n",
    "    l2max = []\n",
    "    DomNum = Nvm*Nvn\n",
    "    sub_x_min = np.empty(DomNum) \n",
    "    sub_x_max = np.empty(DomNum)\n",
    "    sub_y_min = np.empty(DomNum)\n",
    "    sub_y_max = np.empty(DomNum)\n",
    "    el_rownum = np.empty(DomNum)\n",
    "    el_colnum = np.empty(DomNum)\n",
    "    \n",
    "    if 0==Nvm-1:\n",
    "        sub_x_max = np.ones(DomNum)\n",
    "        sub_x_min = np.zeros(DomNum)\n",
    "    else:\n",
    "        for i in range(DomNum):\n",
    "        #generates which row, column each element is in\n",
    "            el_colnum[i] = np.mod(i,Nvm)\n",
    "            if el_colnum[i] == 0:\n",
    "                sub_x_max[i] = (el_colnum[i]+1+h_x)*len_x\n",
    "                sub_x_min[i] = (el_colnum[i])*len_x\n",
    "            elif el_colnum[i] == Nvm-1:\n",
    "                sub_x_min[i] = (el_colnum[i]-h_x)*len_x\n",
    "                sub_x_max[i] = (el_colnum[i]+1)*len_x\n",
    "            else:\n",
    "                sub_x_min[i] = (el_colnum[i]-h_x)*len_x\n",
    "                sub_x_max[i] = (el_colnum[i]+1+h_x)*len_x\n",
    "\n",
    "    if 0==Nvn-1:\n",
    "        sub_y_max = np.ones(DomNum)\n",
    "        sub_y_min = np.zeros(DomNum)\n",
    "    else:\n",
    "        for i in range(DomNum):\n",
    "        #generates which row, column each element is in\n",
    "            el_rownum[i] = int(i/Nvm) \n",
    "\n",
    "            if el_rownum[i]==0:\n",
    "                sub_y_max[i] = (el_rownum[i]+1+h_y)*len_y\n",
    "                sub_y_min[i] = el_rownum[i]*len_y\n",
    "            elif el_rownum[i]==Nvn-1:\n",
    "                sub_y_min[i] = (el_rownum[i]-h_y)*len_y\n",
    "                sub_y_max[i] = (el_rownum[i]+1)*len_y\n",
    "            else:\n",
    "                sub_y_min[i] = (el_rownum[i]-h_y)*len_y\n",
    "                sub_y_max[i] = (el_rownum[i]+1+h_y)*len_y\n",
    "\n",
    "        \n",
    "    u_pred = np.zeros([Nvm*sub_Nvm, Nvn*sub_Nvn])    \n",
    "    top_bounds = np.zeros([DomNum , sub_Nvm])\n",
    "    bottom_bounds = np.zeros([DomNum , sub_Nvm]) \n",
    "    left_bounds = np.zeros([DomNum, sub_Nvn]) \n",
    "    right_bounds = np.zeros([DomNum, sub_Nvn]) \n",
    "    \n",
    "    models = [None]*DomNum\n",
    "    dom_loss_history = np.zeros(epochs)\n",
    "    coarse_loss_history = np.zeros(epochs)\n",
    "    \n",
    "    #initialize boundaries\n",
    "    xzeros = np.zeros(sub_Nvm)\n",
    "    yzeros = np.zeros(sub_Nvn)\n",
    "    xones = np.ones(sub_Nvm)\n",
    "    yones = np.ones(sub_Nvn)\n",
    "    u_coarse = get_model()\n",
    "    for i in range(DomNum):\n",
    "        xline = np.linspace(sub_x_min[i], sub_x_max[i], sub_Nvm)\n",
    "        yline = np.linspace(sub_y_min[i], sub_y_max[i], sub_Nvn)\n",
    "        \n",
    "        if sub_y_min[i] ==0:\n",
    "            bottom_bounds[i, :] = u_exact(p2t(xline, xzeros))\n",
    "            #for j in range(sub_Nvm):\n",
    "             #   bottom_bounds[i, j] = u_exact(p2t(xline[j], 0))\n",
    "        else:\n",
    "            bottom_bounds[i, :] = bound_init(p2t(xline, xzeros))\n",
    "            #for j in range(sub_Nvm):\n",
    "            #   bottom_bounds[i, j] = bound_init([xline[j], sub_y_min[i]])\n",
    "        if sub_y_max[i] ==1:\n",
    "            top_bounds[i, :] = u_exact(p2t(xline, xones))\n",
    "            #for j in range(sub_Nvm):\n",
    "            #    top_bounds[i,j] = u_exact(p2t(xline[j], 1))\n",
    "        else:\n",
    "            top_bounds[i, :] = bound_init(p2t(xline, xones))\n",
    "\n",
    "            #for j in range(sub_Nvm):\n",
    "                #top_bounds[i,j] = bound_init([xline[j], sub_y_max[i]])\n",
    "\n",
    "        if sub_x_min[i]==0:\n",
    "            left_bounds[i, :] = u_exact(p2t(yzeros, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #    left_bounds[i, j] =  u_exact(p2t(0, yline[j]))\n",
    "        else:\n",
    "            left_bounds[i, :] = bound_init(p2t(yzeros, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #   left_bounds[i, j] = bound_init([sub_x_min[i], yline[j]])\n",
    "                \n",
    "        if sub_x_max[i]==1:\n",
    "            right_bounds[i, :] = u_exact(p2t(yones, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #    right_bounds[i, j] = u_exact(p2t(1, yline[j]))\n",
    "        else:\n",
    "            right_bounds[i, :] = bound_init(p2t(yones, yline))\n",
    "            #for j in range(sub_Nvn):\n",
    "            #    right_bounds[i, j] = bound_init([sub_x_max[i], yline[j]])\n",
    "   \n",
    "    #exact_l2 = f_exact(gen_whole_inputs(0, 1, 0, 1, 100, 100))\n",
    "    error_history = np.zeros(epochs)\n",
    "    #xl2 = np.linspace(0, 1, 100)\n",
    "    #yl2 = np.linspace(0, 1, 100)\n",
    "\n",
    "    #Xl2, Yl2 = np.meshgrid(xl2,yl2) \n",
    "    #Xl2_star=np.hstack((Xl2.flatten()[:,None],Yl2.flatten()[:,None]))\n",
    "    \n",
    "    \n",
    "    def u_hat(bound_init, data):\n",
    "        approx = bound_init(data)\n",
    "        if type(approx) == np.ndarray:\n",
    "            output = approx\n",
    "        else:\n",
    "            output = approx.numpy()\n",
    "        for i in range(len(data)):\n",
    "            if data[i, 0]==0 or data[i, 1]==0 or data[i, 1]==1 or data[i, 1]==1:\n",
    "                output[i] = u_exact(tf.expand_dims(data[i, :], axis = 0))\n",
    "\n",
    "        return output\n",
    "    for i in range(DomNum):\n",
    "        models[i] = get_model()\n",
    "        \n",
    "    tol_data = gen_bound_input(0, 1, 0, 1, 100, 100)\n",
    "    flag=False\n",
    "    epoch=0\n",
    "    while epoch<epochs and flag==False: \n",
    "        if epoch ==1: #the second epoch, updates the initializer to be the predictor, so boundary info exchange happens\n",
    "            def bound_init2(data):\n",
    "                output= predictor(models, data)\n",
    "                return output\n",
    "            bound_init = bound_init2\n",
    "\n",
    "        for i in range(DomNum):\n",
    "            pen_param=pen_param_0\n",
    "            lag_mult = lag_mult_0\n",
    "            print(\"Fine Epoch: \"+str(epoch+1) +\"  Subdomain: \"+str(i+1))\n",
    "            (update_model, loss_update) = Eliptic_PINN(models[i], u_hat,bound_init,  top_bounds[i, :], bottom_bounds[i, :], left_bounds[i, :], right_bounds[i, :], sub_x_min[i], sub_x_max[i], sub_y_min[i], sub_y_max[i], sub_Nvm, sub_Nvn, pen_param, max_pen_param, lag_mult)\n",
    "            models[i] = update_model \n",
    "            \n",
    "            dom_loss_history[epoch] = dom_loss_history[epoch]+loss_update[-1]\n",
    "        #Xl2_star=np.hstack((Xl2.flatten()[:,None],Yl2.flatten()[:,None]))\n",
    "        #lambda_f=0.5 replaced in PECANN\n",
    "        print(\"Coarse Epoch: \", epoch+1)\n",
    "        pen_param=pen_param_0\n",
    "        lag_mult1 = lag_mult_0\n",
    "        lag_mult2 = lag_mult_0\n",
    "        (u_coarse, c_loss_update) = train_course(u_coarse, models, max_it, pen_param, max_pen_param,lag_mult1, lag_mult2)\n",
    "        coarse_loss_history[epoch] += c_loss_update[-1]\n",
    "        error_history[epoch] = get_l2(models)\n",
    "        \n",
    "        \n",
    "        #network tolerance criteria for stopping\n",
    "        if epoch==0:\n",
    "            prev_net = predictor(models, tol_data)\n",
    "            prev_norm = tf.reduce_mean(tf.math.square(prev_net))\n",
    "        else:\n",
    "            new_net = predictor(models, tol_data)\n",
    "            net_diff = tf.reduce_mean(tf.math.square(prev_net -new_net))\n",
    "            new_norm = tf.reduce_mean(tf.math.square(new_net))\n",
    "            rel_net_diff = net_diff/min(new_norm, prev_norm)\n",
    "            if rel_net_diff<net_tol:\n",
    "                print(\"Network has converged\")\n",
    "                flag=True\n",
    "            else:\n",
    "                prev_net = new_net\n",
    "                prev_norm = new_norm\n",
    "                \n",
    "        if error_history[epoch]<error_tol:\n",
    "            flag = True\n",
    "            print(\"Error is below tolerance.\")\n",
    "                \n",
    "                \n",
    "        \n",
    "        \n",
    "        \n",
    "        #update bounds with new guesses   \n",
    "        lambda_c = 0.9*(coarse_decay)**epoch\n",
    "        (new_top_bounds, new_bottom_bounds, new_left_bounds, new_right_bounds)= update_bounds_coarse(u_coarse, lambda_c, models, DomNum, sub_x_min, sub_x_max, sub_y_min, sub_y_max, sub_Nvm, sub_Nvn, top_bounds, bottom_bounds, left_bounds, right_bounds, bound_init)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        epoch+=1\n",
    "    \n",
    "    dom_loss_history = dom_loss_history/(DomNum) #Averages over subdomains\n",
    "    \n",
    "    \n",
    "    plt.figure()\n",
    "    for i in range(DomNum):\n",
    "        plt.vlines(x=[sub_x_min[i], sub_x_max[i]], ymin=0, ymax=1)\n",
    "        plt.hlines(y=[sub_y_min[i], sub_y_max[i]], xmin=0, xmax=1)\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(dom_loss_history[np.nonzero(dom_loss_history)], label=\"Fine Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(coarse_loss_history[np.nonzero(coarse_loss_history)], label=\"Coarse Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(error_history[np.nonzero(error_history)], label =\"Relative L2 Error\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"Fine Loss: \"+str(dom_loss_history[np.nonzero(dom_loss_history)]))\n",
    "    print(\"Coarse Loss: \"+ str(coarse_loss_history[np.nonzero(coarse_loss_history)]))\n",
    "    print(\"Error \" +str(error_history[np.nonzero(error_history)]))\n",
    "    np.savetxt(\"PC_Loss_and_error.txt\", (dom_loss_history[np.nonzero(dom_loss_history)],coarse_loss_history[np.nonzero(coarse_loss_history)], error_history[np.nonzero(error_history)]), delimiter =\", \", header= \"Fine Loss, Coarse Loss, Error\")\n",
    "    \n",
    "    return models\n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "95ea3584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_l2(models):\n",
    "    data = gen_whole_inputs(0,1, 0,1, 100, 100)\n",
    "    pred = predictor(models, data)\n",
    "    exact = u_exact(data)\n",
    "    #pred = pred.reshape([100, 100])\n",
    "    error = np.linalg.norm(exact-pred)/np.linalg.norm(exact)\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "99747724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotter(models):\n",
    "    data = gen_whole_inputs(0, 1, 0, 1, 100, 100)\n",
    "    approx = predictor(models, data)\n",
    "    exact = u_exact(data).numpy()\n",
    "    abs_error = abs(exact - approx)\n",
    "    MAE_error = (abs_error).mean()\n",
    "    print(\"Mean Absolute Error: \" + str(MAE_error))\n",
    "    rel_L2_err = np.linalg.norm(exact-approx)/np.linalg.norm(exact) \n",
    "    print(\"Relative L2 Error: \" + str(rel_L2_err))\n",
    "    print(\"Error Max \"+ str(abs_error.max()))\n",
    "    print(\"Error Min \"+ str(abs_error.min()))\n",
    "    x = data[:, 0].numpy()\n",
    "    y = data[:, 1].numpy()\n",
    "    \n",
    "    plt.figure(figsize=(12,12))\n",
    "    ax = plt.subplot(3, 1, 1)\n",
    "    plt.tricontourf(x, y, abs_error ,100)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(label = \"Absolute Error\")\n",
    "    #plt.plot()\n",
    "    \n",
    "    plt.subplot(3, 1, 2)\n",
    "    plt.tricontourf(x, y, approx ,100)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(label = \"Predicted\")\n",
    "    np.savetxt(\"PC_Approx.txt\", approx)\n",
    "    \n",
    "    plt.subplot(3, 1, 3)\n",
    "    plt.tricontourf(x, y, exact ,100)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.colorbar(label = \"Exact\")\n",
    "    np.savetxt(\"PC_Exact.txt\", exact)\n",
    "\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "31136fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xsplice_plt(models, x):\n",
    "    y = np.linspace(0, 1, 100) \n",
    "    data= p2t(np.full(100, x), y)\n",
    "    exact = u_exact(data)\n",
    "    \n",
    "    plt.plot(exact, label = \"X = \"+str(x))\n",
    "    plt.plot(predictor(models, data), label = \"X Approx\")\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c41f171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ysplice_plt(models, y):\n",
    "    x = np.linspace(0, 1, 100) \n",
    "\n",
    "    data = p2t( x, np.full(100, y))\n",
    "\n",
    "\n",
    "    plt.plot(u_exact(data), label = \"Y = \"+str(y))\n",
    "    plt.plot(predictor(models, data), label = \"Y Approx\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e1198730",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_init(data):\n",
    "    return np.zeros(len(data))\n",
    "#for exact initializer put u_exact as the initializer\n",
    "#def random_init(data):\n",
    "#    return np.random.rand(len(data))\n",
    "def avg_init(x, y):\n",
    "    avg = 0.25*((1-x)*u_exact([x, 0])+x*u_exact([x, 1])+(1-y)*u_exact([0, y])+y*u_exact([1, y]))\n",
    "    return avg\n",
    "#def noisy_init(data):\n",
    " #   return u_exact(data)+noise*random_init(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9036e14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nvm = 3 #number of subintervals along x axis\n",
    "Nvn = 3 #number of subintervals along y axis\n",
    "h_x = 0.2 #percentage of overlap (<=1)\n",
    "h_y = 0.2 #percentage of overlap (<=1)\n",
    "epochs = 100\n",
    "sub_Nvm = 100 #mesh for PINN training\n",
    "sub_Nvn = 100\n",
    "max_it = 100 #max_it for PINN training\n",
    "initializer = zero_init #u_exact, zero_init, random_init, avg_init, noisy_init\n",
    "global noise\n",
    "noise = 0.05 #only for noisy initializer\n",
    "#reset_models_betweeen_epochs = True\n",
    "optm = tf.keras.optimizers.legacy.Adam(amsgrad=True)\n",
    "net_tol= 1e-3 #tolerance for network convergeance \n",
    "error_tol = 0.1 #tolerance for error\n",
    "\n",
    "coarse_decay = 0.8 #between 0 and 1. Adjust how fast coarse network influence decays\n",
    "\n",
    "\n",
    "pen_param = 1 #initial penalty parameter\n",
    "max_pen_param  = 10000 #safeguarding penalty parameter\n",
    "lag_mult_0 = 1 #initial param for the MSE_loss term\n",
    "\n",
    "global per_collocation\n",
    "global per_interior\n",
    "global width #width in NN models\n",
    "global depth #depth in NN models\n",
    "global const #PDE constant\n",
    "global int_weight #weight for interior loss, between 0 and 1, higher means more weight on PDE loss than boundary loss\n",
    "int_weight = 0.5\n",
    "const = 3.141592653589793 #math.pi\n",
    "per_collocation = 0.5\n",
    "per_interior = 0.5\n",
    "width  = 20\n",
    "depth  = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc5d14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine Epoch: 1  Subdomain: 1\n",
      "73.614944\n",
      "54.952133\n",
      "43.25372\n",
      "32.59256\n",
      "28.2054\n",
      "25.431234\n",
      "21.68411\n",
      "16.732492\n",
      "11.48255\n",
      "7.7675376\n",
      "Fine Epoch: 1  Subdomain: 2\n",
      "120.75477\n",
      "60.04763\n",
      "47.28392\n",
      "37.437325\n",
      "23.918064\n",
      "10.38434\n",
      "2.9651651\n",
      "2.2153978\n",
      "1.7610022\n",
      "1.6282157\n",
      "Fine Epoch: 1  Subdomain: 3\n",
      "58.841496\n",
      "35.39813\n",
      "25.480125\n",
      "19.178694\n",
      "11.250999\n",
      "4.859808\n",
      "2.993105\n",
      "1.9486476\n",
      "1.4126446\n",
      "1.28544\n",
      "Fine Epoch: 1  Subdomain: 4\n",
      "122.97127\n",
      "24.448103\n",
      "18.681513\n",
      "11.499353\n",
      "6.686137\n",
      "4.397457\n",
      "2.6112256\n",
      "1.4071136\n",
      "0.8504354\n",
      "0.6220917\n",
      "Fine Epoch: 1  Subdomain: 5\n",
      "271.86975\n",
      "101.59209\n",
      "71.41822\n",
      "47.606388\n",
      "33.885754\n",
      "24.687647\n",
      "16.276974\n",
      "13.38702\n",
      "6.4509706\n",
      "4.3068886\n",
      "Fine Epoch: 1  Subdomain: 6\n",
      "115.022316\n",
      "43.099922\n",
      "17.387875\n",
      "9.452926\n",
      "5.5538945\n",
      "3.5228653\n",
      "3.21166\n",
      "2.9680886\n",
      "2.7698827\n",
      "2.618176\n",
      "Fine Epoch: 1  Subdomain: 7\n",
      "58.512188\n",
      "19.377964\n",
      "18.226633\n",
      "9.68445\n",
      "2.983301\n",
      "2.6554053\n",
      "1.961954\n",
      "1.7872534\n",
      "1.7056442\n",
      "1.6293024\n",
      "Fine Epoch: 1  Subdomain: 8\n",
      "139.69257\n",
      "124.823685\n",
      "116.5487\n",
      "89.53164\n",
      "56.418316\n",
      "52.44312\n",
      "32.689293\n",
      "21.079742\n",
      "16.790825\n",
      "12.779555\n",
      "Fine Epoch: 1  Subdomain: 9\n",
      "60.171352\n",
      "53.94479\n",
      "25.705091\n",
      "18.78441\n",
      "13.699753\n",
      "10.609174\n",
      "6.4196177\n",
      "4.025233\n",
      "2.3950365\n",
      "1.8204813\n",
      "Coarse Epoch:  1\n",
      "2690.472\n",
      "266.6052\n",
      "193.00522\n",
      "161.34787\n",
      "150.9526\n",
      "150.81573\n",
      "150.64133\n",
      "149.69644\n",
      "149.14029\n",
      "148.77089\n",
      "Fine Epoch: 2  Subdomain: 1\n",
      "5.1605844\n",
      "1.9962804\n",
      "0.92689496\n",
      "0.40704128\n",
      "0.2596426\n",
      "0.1969264\n",
      "0.17180045\n",
      "0.15933819\n",
      "0.15030393\n",
      "0.14375848\n",
      "Fine Epoch: 2  Subdomain: 2\n",
      "3.4993029\n",
      "5.497989\n",
      "3.7392783\n",
      "2.4766717\n",
      "1.8692485\n",
      "1.7044555\n",
      "1.523187\n",
      "1.3564174\n",
      "1.1768352\n",
      "0.9983178\n",
      "Fine Epoch: 2  Subdomain: 3\n",
      "2.1057258\n",
      "1.921317\n",
      "2.7380834\n",
      "1.5342705\n",
      "1.3204558\n",
      "1.2204452\n",
      "1.108759\n",
      "1.0386008\n",
      "0.991532\n",
      "0.9596199\n",
      "Fine Epoch: 2  Subdomain: 4\n",
      "3.6370692\n",
      "3.7516806\n",
      "2.2514186\n",
      "1.111102\n",
      "0.92273754\n",
      "0.8141248\n",
      "0.77991086\n",
      "0.73063475\n",
      "0.7012008\n",
      "0.6745171\n",
      "Fine Epoch: 2  Subdomain: 5\n",
      "7.616685\n",
      "35.407516\n",
      "7.0432405\n",
      "4.1091685\n",
      "2.5078146\n",
      "1.5498321\n",
      "1.1129738\n",
      "0.96447027\n",
      "0.9199363\n",
      "0.9036525\n",
      "Fine Epoch: 2  Subdomain: 6\n",
      "11.524193\n",
      "49.788895\n",
      "19.966309\n",
      "13.048991\n",
      "9.489003\n",
      "7.112899\n",
      "6.574476\n",
      "6.073244\n",
      "5.860908\n",
      "5.6766458\n",
      "Fine Epoch: 2  Subdomain: 7\n",
      "5.873355\n",
      "6.6494284\n",
      "4.142731\n",
      "3.5786736\n",
      "2.9664705\n",
      "2.5147104\n",
      "2.1950173\n",
      "1.9124888\n",
      "1.68305\n",
      "1.4952091\n",
      "Fine Epoch: 2  Subdomain: 8\n",
      "17.378191\n",
      "9.609026\n",
      "4.6201806\n",
      "4.2100444\n",
      "3.4874115\n",
      "3.0577784\n",
      "2.7251945\n",
      "2.479471\n",
      "2.2746367\n",
      "2.117009\n",
      "Fine Epoch: 2  Subdomain: 9\n",
      "6.130705\n",
      "9.475633\n",
      "3.5952127\n",
      "1.747241\n",
      "1.8266295\n",
      "1.6460824\n",
      "1.5066594\n",
      "1.4558899\n",
      "1.4135116\n",
      "1.3664489\n",
      "Coarse Epoch:  2\n",
      "100.2799\n",
      "104.82053\n",
      "102.93287\n",
      "101.33699\n",
      "100.19822\n",
      "99.43581\n",
      "98.91841\n",
      "98.52695\n",
      "98.175125\n",
      "97.80987\n",
      "Fine Epoch: 3  Subdomain: 1\n",
      "0.67068297\n",
      "0.31502253\n",
      "0.29916045\n",
      "0.1697335\n",
      "0.16404457\n",
      "0.14325179\n",
      "0.1353171\n",
      "0.12856568\n",
      "0.12282534\n",
      "0.11853027\n",
      "Fine Epoch: 3  Subdomain: 2\n",
      "1.9665768\n",
      "0.8038067\n",
      "0.73067147\n",
      "0.4595692\n",
      "0.4348964\n",
      "0.3943314\n",
      "0.38545212\n",
      "0.3769443\n",
      "0.37052798\n",
      "0.36529392\n",
      "Fine Epoch: 3  Subdomain: 3\n",
      "1.33441\n",
      "1.1018509\n",
      "0.9404066\n",
      "0.87862724\n",
      "0.8280032\n",
      "0.7950807\n",
      "0.764595\n",
      "0.73979\n",
      "0.7178524\n",
      "0.6978253\n",
      "Fine Epoch: 3  Subdomain: 4\n",
      "1.6759665\n",
      "0.7486364\n",
      "0.48563656\n",
      "0.3384059\n",
      "0.3381541\n",
      "0.29859522\n",
      "0.2897226\n",
      "0.28303725\n",
      "0.27892488\n",
      "0.27473426\n",
      "Fine Epoch: 3  Subdomain: 5\n",
      "4.951715\n",
      "3.915458\n",
      "0.77273625\n",
      "0.5549074\n",
      "0.6111139\n",
      "0.4792014\n",
      "0.44952518\n",
      "0.4491379\n",
      "0.4407755\n",
      "0.43638158\n",
      "Fine Epoch: 3  Subdomain: 6\n",
      "4.6013193\n",
      "4.4288535\n",
      "3.3299544\n",
      "3.1028788\n",
      "3.0190723\n",
      "2.9320145\n",
      "2.8865573\n",
      "2.845815\n",
      "2.808359\n",
      "2.7742524\n",
      "Fine Epoch: 3  Subdomain: 7\n",
      "1.5105889\n",
      "1.0482196\n",
      "0.8508714\n",
      "0.65686226\n",
      "0.56224155\n",
      "0.50338864\n",
      "0.46271074\n",
      "0.43272611\n",
      "0.4110193\n",
      "0.39364082\n",
      "Fine Epoch: 3  Subdomain: 8\n",
      "2.4006326\n",
      "1.6932131\n",
      "1.2019534\n",
      "0.97533363\n",
      "0.9279138\n",
      "0.88261133\n",
      "0.85505474\n",
      "0.8362066\n",
      "0.8198678\n",
      "0.80537343\n",
      "Fine Epoch: 3  Subdomain: 9\n",
      "1.3322388\n",
      "1.0828038\n",
      "0.81097895\n",
      "0.69423544\n",
      "0.6407421\n",
      "0.5885643\n",
      "0.5379061\n",
      "0.49021482\n",
      "0.4466409\n",
      "0.40721342\n",
      "Coarse Epoch:  3\n",
      "103.71889\n",
      "115.88193\n",
      "114.79477\n",
      "113.9055\n",
      "112.90927\n",
      "111.678375\n",
      "110.186356\n",
      "108.40464\n",
      "106.31905\n",
      "103.96994\n",
      "Fine Epoch: 4  Subdomain: 1\n",
      "0.2114119\n",
      "0.15230456\n",
      "0.092500195\n",
      "0.07522089\n",
      "0.06619177\n",
      "0.059619326\n",
      "0.05474646\n",
      "0.051028028\n",
      "0.048005015\n",
      "0.045457903\n",
      "Fine Epoch: 4  Subdomain: 2\n",
      "0.5954424\n",
      "0.3486858\n",
      "0.29929847\n",
      "0.22598101\n",
      "0.20952368\n",
      "0.20197141\n",
      "0.19683959\n",
      "0.19432756\n",
      "0.19201511\n",
      "0.19003882\n",
      "Fine Epoch: 4  Subdomain: 3\n",
      "0.7666824\n",
      "0.69286954\n",
      "0.6408326\n",
      "0.5990637\n",
      "0.570006\n",
      "0.5497274\n",
      "0.531497\n",
      "0.5146178\n",
      "0.49889317\n",
      "0.48403555\n",
      "Fine Epoch: 4  Subdomain: 4\n",
      "0.55270004\n",
      "0.24060796\n",
      "0.21106996\n",
      "0.16145937\n",
      "0.15584128\n",
      "0.1470654\n",
      "0.14448285\n",
      "0.142298\n",
      "0.14067172\n",
      "0.13920787\n",
      "Fine Epoch: 4  Subdomain: 5\n",
      "0.94582427\n",
      "0.5388496\n",
      "0.14652365\n",
      "0.16305421\n",
      "0.15265913\n",
      "0.12814386\n",
      "0.120429575\n",
      "0.11891248\n",
      "0.11716885\n",
      "0.11558629\n",
      "Fine Epoch: 4  Subdomain: 6\n",
      "1.9951155\n",
      "2.0533154\n",
      "1.8289337\n",
      "1.7565928\n",
      "1.7252364\n",
      "1.7024077\n",
      "1.6792988\n",
      "1.6568513\n",
      "1.6356239\n",
      "1.615172\n",
      "Fine Epoch: 4  Subdomain: 7\n",
      "0.34952044\n",
      "0.28757435\n",
      "0.25959814\n",
      "0.23995782\n",
      "0.22751315\n",
      "0.21860644\n",
      "0.21080863\n",
      "0.20427339\n",
      "0.19825491\n",
      "0.19265302\n",
      "Fine Epoch: 4  Subdomain: 8\n",
      "0.7598887\n",
      "0.70402366\n",
      "0.5805088\n",
      "0.5488527\n",
      "0.53300405\n",
      "0.5234029\n",
      "0.5152022\n",
      "0.5081358\n",
      "0.50180906\n",
      "0.49589756\n",
      "Fine Epoch: 4  Subdomain: 9\n",
      "0.30271733\n",
      "0.31020272\n",
      "0.25831386\n",
      "0.23693806\n",
      "0.22582662\n",
      "0.219394\n",
      "0.21380071\n",
      "0.20869565\n",
      "0.20424777\n",
      "0.20029022\n",
      "Coarse Epoch:  4\n",
      "99.62105\n",
      "113.36298\n",
      "109.43378\n",
      "107.07984\n",
      "105.43969\n",
      "104.35185\n",
      "103.2714\n",
      "102.17195\n",
      "101.03289\n",
      "99.85729\n",
      "Fine Epoch: 5  Subdomain: 1\n",
      "0.06800842\n",
      "0.05911015\n",
      "0.036167473\n",
      "0.031012768\n",
      "0.027941288\n",
      "0.0256626\n",
      "0.023936206\n",
      "0.022453245\n",
      "0.021139272\n",
      "0.019974936\n",
      "Fine Epoch: 5  Subdomain: 2\n",
      "0.21926533\n",
      "0.1708053\n",
      "0.13566042\n",
      "0.12639956\n",
      "0.12275474\n",
      "0.11965955\n",
      "0.11788579\n",
      "0.11666151\n",
      "0.11549497\n",
      "0.11436917\n",
      "Fine Epoch: 5  Subdomain: 3\n",
      "0.46496528\n",
      "0.43788522\n",
      "0.411242\n",
      "0.38807473\n",
      "0.36987543\n",
      "0.35568994\n",
      "0.3429014\n",
      "0.33094493\n",
      "0.31957534\n",
      "0.3086196\n",
      "Fine Epoch: 5  Subdomain: 4\n",
      "0.17406827\n",
      "0.14506623\n",
      "0.10367254\n",
      "0.09817708\n",
      "0.09575043\n",
      "0.093494676\n",
      "0.09181278\n",
      "0.09043455\n",
      "0.08922378\n",
      "0.08812267\n",
      "Fine Epoch: 5  Subdomain: 5\n",
      "0.19159098\n",
      "0.13267498\n",
      "0.07005571\n",
      "0.056176197\n",
      "0.05286945\n",
      "0.05063303\n",
      "0.048433032\n",
      "0.046998963\n",
      "0.045993242\n",
      "0.045198817\n",
      "Fine Epoch: 5  Subdomain: 6\n",
      "1.2568204\n",
      "1.3000461\n",
      "1.2504225\n",
      "1.2219028\n",
      "1.1972984\n",
      "1.180417\n",
      "1.1656399\n",
      "1.151125\n",
      "1.1371009\n",
      "1.1234552\n",
      "Fine Epoch: 5  Subdomain: 7\n",
      "0.15188363\n",
      "0.16335635\n",
      "0.1505962\n",
      "0.14651504\n",
      "0.14221352\n",
      "0.13905032\n",
      "0.13624011\n",
      "0.13379943\n",
      "0.13152415\n",
      "0.12938365\n",
      "Fine Epoch: 5  Subdomain: 8\n",
      "0.41095442\n",
      "0.42880133\n",
      "0.40804526\n",
      "0.3910467\n",
      "0.38316536\n",
      "0.37756893\n",
      "0.3734043\n",
      "0.3696918\n",
      "0.36635128\n",
      "0.36316574\n",
      "Fine Epoch: 5  Subdomain: 9\n",
      "0.16279356\n",
      "0.2196495\n",
      "0.20675652\n",
      "0.19769259\n",
      "0.19184639\n",
      "0.18812901\n",
      "0.18518741\n",
      "0.18273725\n",
      "0.18059573\n",
      "0.17866087\n",
      "Coarse Epoch:  5\n",
      "88.473595\n",
      "111.066986\n",
      "109.684105\n",
      "108.034225\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "models = DeepDDM(Nvm, Nvn, h_x, h_y, epochs, sub_Nvm, sub_Nvn, initializer, pen_param, max_pen_param, lag_mult_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaaa144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotter(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0827567",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsplice_plt(models, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ysplice_plt(models, 0.50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6925ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
